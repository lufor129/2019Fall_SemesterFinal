{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取ettoday (最好爬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "from lxml import etree\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import pymongo\n",
    "from tqdm import trange,tqdm\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument('--headless')\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"semester\"]\n",
    "mycol = mydb[\"ettoday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_j = {\n",
    "    \"8\":31,\"9\":30,\"10\":31,\"11\":30,\"12\":31\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ettoday.net/news/news-list-2019-{}-{}-0.htm\"\n",
    "def getDateNews(mon,date,D):\n",
    "    links = []\n",
    "    tags = []\n",
    "    response = requests.get(url.format(mon,date))\n",
    "    html = etree.HTML(response.content)\n",
    "    links = html.xpath(\"//div[@class='part_list_2']/h3/a/@href\")\n",
    "    links = [\"https://www.ettoday.net\"+link for link in links]\n",
    "    tags = html.xpath(\"//div[@class='part_list_2']/h3/em/text()\")\n",
    "    data = {\"offset\": 1,\"tPage\": 3,\"tFile\": D+\".xml\",\"tOt\": 0,\"tSi\": 100,\"tAr\":0}\n",
    "    for i in range(1,69):\n",
    "        data[\"offset\"] = i\n",
    "        response = requests.post(\"https://www.ettoday.net/show_roll.php\",data=data)\n",
    "        html = etree.HTML(response.text)\n",
    "        h3 = html.xpath(\"//h3\")\n",
    "        for k in h3:\n",
    "            links.append(\"https://www.ettoday.net\"+k.xpath(\".//a/@href\")[0])\n",
    "            tags.append(k.xpath(\".//text()\")[1])\n",
    "    return tags,links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 用selenium寫，效果不好，太慢了\n",
    "url = \"https://www.ettoday.net/news/news-list-2019-{}-{}-0.htm\"\n",
    "def getDateNews(mon,date,D):\n",
    "    driver.get(url.format(mon,date))\n",
    "    time.sleep(2)\n",
    "    for i in range(80):\n",
    "        if(i==10 or i== 20):\n",
    "            driver.execute_script(\"window.scrollTo(document.body.scrollHeight,0)\")\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(0.2)\n",
    "    news = driver.find_elements_by_xpath(\"//div[@class='part_list_2']/h3/a\")\n",
    "    links = [link.get_attribute(\"href\") for link in news]\n",
    "    tags_ = driver.find_elements_by_xpath(\"//div[@class='part_list_2']/h3/em\")\n",
    "    tags = [tag.text for tag in tags_]\n",
    "    return tags,links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnews(link,D,tag):\n",
    "    try: \n",
    "        response = requests.get(link)\n",
    "        tag = tag\n",
    "        html = etree.HTML(response.content,parser=etree.HTMLParser(encoding='utf-8'))\n",
    "        link = link\n",
    "        title = html.xpath(\"//header/h1/text()\")\n",
    "        title = title[0].strip()\n",
    "        contents = html.xpath(\"//div[@class='story']/p/text()\")\n",
    "        content = \"\\n\".join([content.strip()for content in contents])\n",
    "        img_link = html.xpath(\"//div[@class='story']//img/@src\")[0]\n",
    "        pic = requests.get(\"https:\"+img_link)\n",
    "        link_id = link.split(\"/\")[-1].split(\".\")[0]\n",
    "        time = html.xpath(\"//time/@datetime\")[0]\n",
    "        time = time.replace(\"+08:00\",\"\").replace(\"T\",\"_\").replace(\":\",\"-\")\n",
    "        img_path = \"./pic/\"+D+\"/\"+time+\"_\"+link_id+\".png\"\n",
    "        open(img_path,\"wb\").write(pic.content)\n",
    "        insert_dict = {\"title\":title,\"content\":content,\"time\":time,\"tag\":tag,\"link\":link,\"img_path\":img_path}\n",
    "        mycol.update_one({\"link\":insert_dict[\"link\"]},{\"$set\":insert_dict},upsert=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crawlDateNews(tags,links,D):\n",
    "    threads = []\n",
    "    for i,link in enumerate(links):\n",
    "        date = link.split('/')[-2]        \n",
    "        if(date != D or mycol.find_one({\"link\":link}) != None):\n",
    "            continue\n",
    "        threads.append(threading.Thread(target=getnews,args=(link,D,tags[i])))\n",
    "\n",
    "    ## 成功，多執行續!!!!\n",
    "    q = queue.Queue(16)\n",
    "    while(len(threads)):\n",
    "        if(q.qsize() >= 16):\n",
    "            thread = q.get()\n",
    "            thread.start()\n",
    "            continue\n",
    "        else:\n",
    "            q.put(threads.pop())\n",
    "\n",
    "    while(q.qsize()>0):\n",
    "        thread = q.get()\n",
    "        thread.start()\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 08: 100%|████████████████████████████████████████████████████████████████████████| 31/31 [10:20<00:00, 20.01s/it]\n",
      "Month 09: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [13:13<00:00, 26.45s/it]\n",
      "Month 10: 100%|████████████████████████████████████████████████████████████████████████| 31/31 [28:06<00:00, 54.40s/it]\n",
      "Month 11: 100%|████████████████████████████████████████████████████████████████████████| 30/30 [34:53<00:00, 69.80s/it]\n",
      "Month 12: 100%|██████████████████████████████████████████████████████████████████████████| 2/2 [01:28<00:00, 44.46s/it]\n"
     ]
    }
   ],
   "source": [
    "m = time.strftime(\"%m\",time.localtime(time.time()))\n",
    "d = time.strftime(\"%d\",time.localtime(time.time()))\n",
    "mo = int(m)\n",
    "da = int(d)\n",
    "for j in range(8,mo+1):\n",
    "    mon = j\n",
    "    date = month_j[str(mon)]\n",
    "    if(j==mo):\n",
    "        date = da\n",
    "    m = \"0\"+str(mon) if mon <10 else mon\n",
    "    for i in tqdm(range(1,date+1),desc=\"Month \"+str(m)):\n",
    "        d = \"0\"+str(i) if i <10 else i\n",
    "        D = \"2019\"+str(m)+str(d)\n",
    "        directory = \"./pic/\"+D\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        tags,links = getDateNews(str(mon),str(i),D)\n",
    "        crawlDateNews(tags,links,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
