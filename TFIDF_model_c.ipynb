{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import pymongo\n",
    "from gensim import corpora, models, similarities\n",
    "jieba.set_dictionary(\"dict.txt.big.txt\")\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"semester\"]\n",
    "mycol = mydb[\"ettoday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['快訊／高嘉瑜晚間好奇找阿北求證\\u3000柯P終於「一句話」解答了', '美眉的夏天／最HOT名單出爐\\u3000她激戰搶下冠軍抱千元大獎', '搭西寧軍艦南偵\\u300022名教師登太平島深化主權意識', '桃園區慶讚中元水燈排車繞境\\u3000傳承百年特色慶典', '鳳飛飛故事展、電影展…等紀念活動\\u3000緬懷永遠的國民天后', '韓國瑜選總統8月3日從桃園出發\\u3000要讓全國看到藍軍團結力量', '規劃「個人服裝包」\\u3000國軍新兵服裝用APP快速搞定', '嘉義「火燈夜巡、大士爺祭」深獲在地認同\\u3000下一步推向國際', '台民黨「不分區名單」她第一個被點名！\\u3000柯文哲傾向不選才組黨', '影／她吃藥睡死…起床驚見「手被蟑螂咬」模樣超慘\\u3000網加碼曝：而且非常痛']\n"
     ]
    }
   ],
   "source": [
    "ettoday_list = []\n",
    "for i in mycol.find({},{\"title\":1,\"_id\":0}):\n",
    "    ettoday_list.append(i[\"title\"])\n",
    "print(ettoday_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\program\\semester_final\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\PC-Henry\\AppData\\Local\\Temp\\jieba.u202fd84447beda33a25aefd770cfa382.cache\n",
      "Loading model cost 1.280 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['高嘉瑜', '晚間', '好奇', '找', '阿北', '求證', '柯', 'P', '終於', '一句', '話', '解答', '了'], ['美眉', '的', '夏天', '最', 'HOT', '名單', '出爐', '她', '激戰', '搶下', '冠軍', '抱', '千元', '大獎'], ['搭', '西寧', '軍艦', '南偵', '22', '名', '教師', '登', '太平島', '深化', '主權', '意識'], ['桃園', '區', '慶', '讚', '中', '元', '水燈', '排車', '繞境', '傳承', '百年', '特色', '慶典'], ['鳳飛飛', '故事', '展', '電影展', '等', '紀念活動', '緬懷', '永遠', '的', '國民', '天后'], ['韓國', '瑜', '選', '總統', '8', '月', '3', '日', '從', '桃園', '出發', '要', '讓', '全國', '看到', '藍', '軍', '團結', '力量'], ['規劃', '個人', '服裝', '包', '國軍', '新兵', '服裝', '用', 'APP', '快速', '搞定'], ['嘉義', '火燈', '夜巡', '大士', '爺祭', '深獲', '在', '地', '認同', '下', '一步', '推向', '國際'], ['台', '民黨', '不', '分區', '名單', '她', '第一個', '被', '點名', '柯文', '哲', '傾向', '不選才', '組黨'], ['影', '她', '吃藥', '睡死', '起床', '驚見', '手', '被', '蟑螂', '咬', '模樣', '超', '慘網', '加碼', '曝', '而且', '非常', '痛']]\n"
     ]
    }
   ],
   "source": [
    "def clean_data(title):\n",
    "    sub_t = \"\\W+\"\n",
    "    t_sub = re.sub(sub_t,\"\",title)\n",
    "    t_sub = re.sub(\"快訊\",\"\",t_sub)\n",
    "    return list(jieba.cut(t_sub))\n",
    "\n",
    "ettoday_list = [clean_data(t) for t in ettoday_list]\n",
    "print(ettoday_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_dict_path = './model/corpora_dict.dict'\n",
    "tfidf_model_path = \"./model/tfidf.model\"\n",
    "index_path = \"./model/simIndex.index\"\n",
    "lsi_model_path = \"./model/lsi_model.lsi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(ettoday_list)\n",
    "dictionary.save(corpora_dict_path)\n",
    "corpus = [dictionary.doc2bow(text) for text in ettoday_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "lsi = models.LsiModel(tfidf[corpus], id2word=dictionary, num_topics=300)\n",
    "index = similarities.SparseMatrixSimilarity(lsi[corpus],num_features = len(dictionary.token2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.save(tfidf_model_path)\n",
    "index.save(index_path)\n",
    "lsi.save(lsi_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = corpora.Dictionary(ettoday_list)\n",
    "# dictionary.save(corpora_dict_path)\n",
    "\n",
    "# corpus = [dictionary.doc2bow(text) for text in ettoday_list]\n",
    "# # corpora.MmCorpus.serialize('./corpus.mm', corpus) \n",
    "\n",
    "# tfidf = models.TfidfModel(corpus)\n",
    "# tfidf.save(tfidf_model_path)\n",
    "\n",
    "# index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = len(dictionary.token2id))\n",
    "# index.save(index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import pymongo\n",
    "from gensim import corpora, models, similarities\n",
    "import pandas as pd\n",
    "jieba.set_dictionary(\"dict.txt.big.txt\")\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"semester\"]\n",
    "mycol = mydb[\"ettoday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import keras\n",
    "model = load_model(\"./model/LSTM_model3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./clean_data/tokenized2.pickle\",\"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_dict_path = './model/corpora_dict.dict'\n",
    "tfidf_model_path = \"./model/tfidf.model\"\n",
    "index_path = \"./model/simIndex.index\"\n",
    "lsi_model_path = \"./model/lsi_model.lsi\"\n",
    "\n",
    "tfidf = models.TfidfModel.load(tfidf_model_path)\n",
    "dictionary = corpora.Dictionary.load(corpora_dict_path)\n",
    "index = similarities.SparseMatrixSimilarity.load(index_path)\n",
    "lsi =  models.LsiModel.load(lsi_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(sentence):\n",
    "    sentence = re.sub(\"快訊\",\"\",sentence)\n",
    "    sentence = re.sub(\"\\W+\",\"\",sentence)\n",
    "    texts = jieba.cut(sentence)\n",
    "    arr = []\n",
    "    for t in texts:\n",
    "        if(t.isdigit() or re.search(\"[^a-zA-Z]+\",t) == None):\n",
    "            arr.append(t)\n",
    "            continue\n",
    "        else:\n",
    "            for tee in t:\n",
    "                arr.append(tee)\n",
    "    return \" \".join(arr)\n",
    "\n",
    "def stringify(text):\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = '\\W+'\n",
    "def clean_mark(text):\n",
    "    text = re.sub(\"快訊\",\"\",text)\n",
    "    text = re.sub(r,\"\",text)\n",
    "    words = jieba.cut(text)\n",
    "    return \" \".join([word for word in words])\n",
    "def stringify(text):\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ettoday = []\n",
    "for i in mycol.find({},{\"title\":1}):\n",
    "    all_ettoday.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSims(sentence):\n",
    "    texts = jieba.cut(sentence)\n",
    "    new_vec = dictionary.doc2bow(texts)\n",
    "    new_vec_tfidf = tfidf[new_vec]\n",
    "    new_vec_lsi = lsi[new_vec_tfidf]\n",
    "    return index[new_vec_lsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"螺絲起子直接刮MINI百萬愛車！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(sentence):\n",
    "    texts = jieba.cut(sentence)\n",
    "    new_vec = dictionary.doc2bow(texts)\n",
    "    new_vec_tfidf = tfidf[new_vec]\n",
    "    return index[new_vec_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = getS(user_input)\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(23761, 0.5972205), (35902, 0.5773784), (39645, 0.5623006), (15875, 0.5001459), (16829, 0.46768466), (29716, 0.45888713), (6844, 0.4438838), (26995, 0.4154801), (19936, 0.40443608), (48365, 0.40166098)]\n",
      "{'_id': ObjectId('5da6f18459aa7d15bc182729'), 'title': '螺絲起子直接刮MINI百萬愛車！\\u3000蔡阿嘎一刀未剪實測「＄899防刮神器」：ＸＸ娘咧'}\n",
      "{'_id': ObjectId('5da6f49f59aa7d15bc185696'), 'title': '鳳鼻隧道限高4.6m…曳引車「繞道強闖」卡住！頂部電纜毀恐賠百萬'}\n",
      "{'_id': ObjectId('5da6f5a659aa7d15bc186535'), 'title': '保險業App首創！南山人壽「直接串接」健保署資料庫'}\n",
      "{'_id': ObjectId('5da6ef9059aa7d15bc18085b'), 'title': '楊慶煌百萬名車遭路樹壓垮\\u3000窗戶殘骸飛滿地心痛'}\n",
      "{'_id': ObjectId('5da6efc159aa7d15bc180c15'), 'title': '馬東石新作揪張基龍打爆罪犯！金亞中轉身辣翻\\u3000預告點破百萬'}\n",
      "{'_id': ObjectId('5da6f31659aa7d15bc183e6c'), 'title': '蜂農痛心！\\u3000養蜂場314蜂箱500萬隻蜂「遭下毒」損失破百萬'}\n",
      "{'_id': ObjectId('5da6ed7f59aa7d15bc17e514'), 'title': '基隆大樓突降恐怖「玻璃雨」\\u3000百萬名車Mini Cooper衰遭砸'}\n",
      "{'_id': ObjectId('5da6f25b59aa7d15bc1833cb'), 'title': '正宮心意決...砸百萬曝「超胸照」連載搭機離台！頭版政治淪背景\\u3000網：求後續'}\n",
      "{'_id': ObjectId('5da6f09759aa7d15bc181838'), 'title': '地產哥出門飆百萬名車\\u3000發動瞬間「點燃駕駛座炸彈」臀部當場炸出血花！'}\n",
      "{'_id': ObjectId('5da6f84659aa7d15bc188745'), 'title': '老翁圍觀砂石車撞爛轎車\\u3000「爆血遺體面孔」驚覺眼熟…直接迴轉哭喊：兒子！'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(getTFIDF[:10])\n",
    "[print(all_ettoday[sim[0]]) for sim in sims[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5da6f18459aa7d15bc182729'), 'title': '螺絲起子直接刮MINI百萬愛車！\\u3000蔡阿嘎一刀未剪實測「＄899防刮神器」：ＸＸ娘咧', 'content': '記者張筱涵／綜合報導\\nYouTuber蔡阿嘎推出的新單元「網路購物大破解」來到第三集，這次要實測網路上廣告超多的價值台幣899元防刮神器，看見廣告內容說是「在刮痕上塗一塗就不用去烤漆」，他還特別買威力加強版，接著親自拿螺絲起子刮自己的MINI百萬愛車做實驗，結果讓他大飆髒話。\\n蔡阿嘎在網友推薦下花了台幣899元買威力加強版的防刮神器，一開始先塗在本身就被刮到的小刮痕上測試，因為老闆有交代「先用海綿圓圓地推開且要有耐心」，他連續塗抹5分鐘後拿出抹布，強調一刀未剪且要攝影師鏡頭拉近對焦，結果一把泥擦掉，一看到刮痕還在：「一模一樣，ＸＸ娘咧。」\\n因為前面有和大頭佛說好要親自刮車測試，蔡阿嘎拿出螺絲起子刮了大約5公分的刮痕，馬上拿防刮神器同樣抹5分鐘，最後還是一點變化都沒有讓他氣得飆罵：「ＸＸ娘咧！真的沒有效！如果老闆你覺得我弄錯了，你他Ｘ的下面留言我看你怎麼弄！」\\n同樣有買過的網友也怒分享「對！我他Ｘ買過，塗了快20分鐘，除了車子一堆白膠，什麼Ｘ用都沒有」，同時原本有打算買的網友也跟著感謝蔡阿嘎實測。另外，部分做相關產業的網友也特別留言指出，「我爸做汽車烤漆的常常在說，如果有這麼簡單用掉我們這些烤漆師傅就不用生存了」、「我是一個汽車美容的店家！感謝這部影片拍給一堆腦弱的人看！」', 'time': '2019-09-06_11-07-00', 'tag': '影劇', 'link': 'https://www.ettoday.net/news/20190906/1529767.htm', 'img_path': './pic/20190906/2019-09-06_11-07-00_1529767.png'}\n",
      "{'_id': ObjectId('5da6f49f59aa7d15bc185696'), 'title': '鳳鼻隧道限高4.6m…曳引車「繞道強闖」卡住！頂部電纜毀恐賠百萬', 'content': '記者陳凱力、莊智勝／新竹報導\\n新竹一名52歲的劉姓男子25日凌晨2時許駕駛曳引車行經鳳鼻隧道，明知車身高度過高，但劉男仍是選擇無視，還特意繞過限高架強闖駛進隧道中，才前行沒多久旋即遭到天花板卡住、動彈不得。警方到場後花了1個半小時才終於成功協助脫困，後續劉男除了得面對至少3000元的罰單外，還得面臨隧道天花板纜線包商求償，粗估目前損失就已達數百萬元。\\n警方調查，劉男深夜駕駛曳引車自高雄北上，行經新竹鳳鼻隧道前即已看到「限高4.6公尺」的限高架，但劉男卻心存僥倖，明知自己曳引車後載運散裝水泥儲存槽，高度達5.03公尺、超高0.43公尺，但仍試圖強闖隧道，還在快速公路上稍作停頓，接著倒車、右轉改道繞過限高架再駛進隧道，不料才剛前行不久，旋即在86公尺處卡住，動彈不得。\\n警方獲報後偕同西濱北二工務段人員到場處理，原本試圖使用輪胎洩壓方式脫困，無奈水泥儲存槽超高太多，車胎洩壓減高後仍是無用，最後只好拆掉隧道天花板，前前後後共折騰了1個半小時，劉男才終於得以脫困，倒車駛離隧道。\\n鳳岡所副所長羅崇義表示，劉男車輛超高逾1公尺，依規定開出3000元以上、9000元以下罰單，後續也將再設限高架，避免用路人「鑽漏洞」。此外，由於最後劉男是透過人工拆除天花板隧道方式脫困，導致內部送電進入機房之纜線、纜線架受損，目前損傷正由包商清點、估算中，粗估損失已達數百萬元，倘若纜線毀損更嚴重一些、需要整條抽換的話，數字也有突破千萬元的可能；後續待包商估算完畢後，將一併向劉男求償。', 'time': '2019-09-25_17-24-00', 'tag': '社會', 'link': 'https://www.ettoday.net/news/20190925/1543167.htm', 'img_path': './pic/20190925/2019-09-25_17-24-00_1543167.png'}\n",
      "{'_id': ObjectId('5da6f5a659aa7d15bc186535'), 'title': '保險業App首創！南山人壽「直接串接」健保署資料庫', 'content': '財經中心／台北報導\\n南山人壽1日宣布，將推動「健康存摺」應用服務，提升核保流程的便利性。內容指出，南山保戶未來再向南山人壽投保時，若核保評估需要提供相關就診紀錄，可選擇透過「南山人壽行動智慧網」App直接串接健保署「健康存摺」，即可下載特定期間的就診資料並授權同意提供南山人壽進行核保作業，大幅簡化投保作業流程。\\n南山人壽表示，秉持「持續從客戶的角度思考」的服務精神，用同理心設想如何提供更創新、更優質的服務品質。南山人壽App成功與健保署的「健康存摺」資料庫直接串接，以「創新」的精神，大幅簡化投保作業流程，致力提供保戶便捷貼心的優質服務。\\n保戶未來再向南山人壽投保時，就能夠透過此服務加速投保、核保時效，同時加速整體流程效率，藉由APP串接使個資不落地的作法，也讓保戶更安心。\\n據了解，「健康存摺」系統於2014年在健保署官網上線，提供民眾查詢個人的就醫紀錄、手術、用藥、檢驗檢查等各項資料之線上服務，並入選「2019智慧城市創新應用獎——政府智慧治理組」智慧醫療獎項。\\n截至今年8月底，「健康存摺」登入及使用人數達142萬人，使用人次約為1581萬人次。為了擴大服務應用，健保署也於今年開放「軟體開發套件」（Software Development Kit, SDK）功能供第三方介接，共同創造健康資料的多元應用。南山人壽率先接洽申請，經過健保署審核通過後，與「南山人壽行動智慧網」App串聯成功，是保險業首次應用「健康存摺」於核保服務上。\\n南山人壽指出，此次首創將「健康存摺」應用於核保流程，當南山人壽既有保戶再次投保時，若經核保評估有需要請保戶提供就診紀錄，保戶即可選擇e化的管道，直接透過「南山人壽行動智慧網」App進入「健康存摺」，於授權同意之範圍內利用SDK串接功能直接提供就醫資料，縮短過去保戶必須跑醫院診所申請文件的冗長流程。\\n民眾若想要完成「健康存摺」的註冊及認證，現在也已開放能透過「手機快速認證方式」，完成健保卡註冊和行動裝置綁定，程序更為簡便，登錄之後，即可隨時掌握自己的健康資訊，管理自我健康。\\n南山人壽表示，此次雖然是透過App介接健保署建置的「健康存摺」，民眾對自身健康資料仍保有高度的自主權，可自行決定是否提供資料及提供資料的範圍，同時為保護個資，在提供前需經過嚴謹的身分認證程序，在傳遞資料前也會提醒民眾再次確認，而資料傳輸過程的安全性也受到高度保障，降低個資外洩風險，相較於民眾自行下載後再以電子郵件方式傳遞更加安全。\\n南山人壽的個資蒐集、處理及利用等作業，都依照現行法規辦理，「個資不落地」的作法，也讓保戶可以更放心。', 'time': '2019-10-01_16-29-00', 'tag': '保險', 'link': 'https://www.ettoday.net/news/20191001/1547317.htm', 'img_path': './pic/20191001/2019-10-01_16-29-00_1547317.png'}\n",
      "{'_id': ObjectId('5da6ef9059aa7d15bc18085b'), 'title': '楊慶煌百萬名車遭路樹壓垮\\u3000窗戶殘骸飛滿地心痛', 'content': '記者李欣容／台北報導\\n資深藝人楊慶煌愛車昨日停在同安街「紀州庵停車場」被路樹壓倒，車頂塌陷、後擋風玻璃也直接碎裂，剛牽不到4個月的百萬名車殘骸滿地，卻求助無門，他氣憤喊，「這棵樹其實是有病的，台北市不知道還有多少這樣的樹，如果砸到的是人怎麼辦？市長你看到了嗎？」\\n楊慶煌今（25日）和兩位受害車主在事發地點開記者會，透露當時大樹倒下艷陽高照，並不是風災影響，且樹本身有病，已經無法存活，卻也沒有相關單位主動處理，「下次碰到人怎麼辦，台北到底還有多少這樣的樹，還是說台北市市民沒有花時間理解這些樹其實有病，這棵樹倒了，我不知道市長你看到了沒，你在拼黨權的時候，注意一下老百姓身家安全好不好。」\\n受害者之一的黃小姐表示，釀禍的大樹似乎有保險，希望相關單位出面協助後續修繕費用，楊慶煌深藍色轎車剛牽4個多月，180萬還在繳貸款，見愛車車頂塌陷，車窗碎滿地，難怪心痛。', 'time': '2019-08-25_11-01-00', 'tag': '影劇', 'link': 'https://www.ettoday.net/news/20190825/1520833.htm', 'img_path': './pic/20190825/2019-08-25_11-01-00_1520833.png'}\n",
      "{'_id': ObjectId('5da6efc159aa7d15bc180c15'), 'title': '馬東石新作揪張基龍打爆罪犯！金亞中轉身辣翻\\u3000預告點破百萬', 'content': '記者吳孟庭／綜合報導\\n馬東石演惡角演上癮，在新片《電影版 壞傢伙們》繼續以暴制暴，改編自19禁（韓國指的是限制級電影）同名電視劇，他飾演被判刑28年的罪犯，再加入張基龍、金亞中等全新班底，首支預告已突破百萬點閱，期待感爆棚，而這部片也即將在台上映。\\n韓劇《壞傢伙們》在2014年曾被列為19禁電視劇，要分級才能收看，卻締造電視台開台收視紀錄，接著續作《壞傢伙們：惡的都市》更寫下4.797%的收視新高。原本就是固定班底的馬東石，同樣演出《電影版 壞傢伙們》，再找來《醜女大翻身》女主角金亞中、《WWW：請輸入檢索詞》張基龍，打造痛快動作爽片！\\n馬東石在劇中飾演朴雄哲一角，被喻為「傳說中的拳頭」，原本被判刑28年的他，在刑警吳九卓（金相中飾演）的網羅下，以減刑的條件加入特殊犯罪調查組，是團隊中重要的人物。\\n馬東石開玩笑地說：「被判刑28年的話，好像真的是個很壞的傢伙，大家不能做壞事喔！」他也表示當初很高興能接演這個角色，也認為「朴雄哲」這個人物很適合出現在犯罪娛樂電影中，「我可以藉由這個角色感到滿足，懲罰壞人。但比起可怕的形象，這個人物滿有喜感的，希望大家都能看得愉快。」\\n影迷對於電影版抱持高度期待，日前韓國片商於Facebook粉絲專頁公布首支預告，已突破105萬瀏覽人次，約2.5萬名用戶按讚、1萬多則留言、近2千次的分享，網友大讚「動作犯罪片還是要看馬東石最對味」、「張基龍眼神帥翻，穿囚服打鬥也很殺」、「電視劇版結束後等好久，終於能在大銀幕看馬東石盡情使壞了！」\\n《電影版 壞傢伙們》敘述因囚車翻覆而讓一名罪大惡極的罪犯逃脫，警方為了要逮捕這名犯人，再度啟動「特殊犯罪調查組」，祕密進行逮捕計畫。「瘋狗」總指揮吳九卓與朴雄哲，帶領新加入的「感性騙子」郭魯順（金亞中飾）、前刑警高柳盛（張基龍 飾），組成全新隊伍，將他們繩之以法！《電影版 壞傢伙們》預計10月4日在台上映。', 'time': '2019-08-26_22-44-00', 'tag': '影劇', 'link': 'https://www.ettoday.net/news/20190826/1521848.htm', 'img_path': './pic/20190826/2019-08-26_22-44-00_1521848.png'}\n"
     ]
    }
   ],
   "source": [
    "input_id = [all_ettoday[sim[0]][\"_id\"] for sim in sims[:5]]\n",
    "# print(input_id)\n",
    "for i in input_id:\n",
    "    print(mycol.find_one({\"_id\":i}))\n",
    "# for i in mycol.find({\"_id\":{\"$in\":input_id}},{\"title\":1,\"_id\":1,\"link\":1,\"img_path\":1}):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_num = 10\n",
    "input_data = [all_ettoday[sim[0]][\"title\"] for sim in sims[:top_num]]\n",
    "# print(input_data)\n",
    "input_data = pd.DataFrame(input_data)\n",
    "input_data.columns = [\"title2\"]\n",
    "input_data[\"title1\"] = user_input\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 25\n",
    "input_data['title1_tokenized'] = \\\n",
    "    input_data.loc[:, 'title1'].apply(stringify).apply(cleanData)\n",
    "input_data['title2_tokenized'] = \\\n",
    "    input_data.loc[:, 'title2'].apply(stringify).apply(cleanData)\n",
    "\n",
    "# 將詞彙序列轉為索引數字的序列\n",
    "x1_test = tokenizer \\\n",
    "    .texts_to_sequences(\n",
    "        input_data.title1_tokenized)\n",
    "x2_test = tokenizer \\\n",
    "    .texts_to_sequences(\n",
    "        input_data.title2_tokenized)\n",
    "\n",
    "# 為數字序列加入 zero padding\n",
    "x1_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(\n",
    "        x1_test, \n",
    "        maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x2_test = keras \\\n",
    "    .preprocessing \\\n",
    "    .sequence \\\n",
    "    .pad_sequences(\n",
    "        x2_test, \n",
    "        maxlen=MAX_SEQUENCE_LENGTH)    \n",
    "\n",
    "# 利用已訓練的模型做預測\n",
    "predictions = model.predict(\n",
    "    [x1_test, x2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_to_index = {\n",
    "    'unrelated': 0, \n",
    "    'agreed': 1, \n",
    "    'disagreed': 2\n",
    "}\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "\n",
    "input_data['Category'] = [index_to_label[idx] for idx in np.argmax(predictions, axis=1)]\n",
    "input_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2_num = {\n",
    "    0: 0, \n",
    "    1: 1, \n",
    "    2: -1\n",
    "}\n",
    "lsi_index = [sim[0] for sim in sims[:top_num]]\n",
    "lsi_sims = [sim[1] for sim in sims[:top_num]]\n",
    "pred_label = [label_2_num[idx] for idx in np.argmax(predictions, axis=1)]\n",
    "\n",
    "score = 0.\n",
    "\n",
    "for i in range(len(lsi_index)):\n",
    "    score += lsi_sims[i]*pred_label[i]\n",
    "    \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_label)\n",
    "print(lsi_sims)\n",
    "print(np.argmax(predictions, axis=1))\n",
    "print(predictions)\n",
    "print(predictions[range(10),np.argmax(predictions, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(round(0.7069477,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgeScore(score):\n",
    "    if(score<2.5):\n",
    "        return \"我們猜應該是假新聞\"\n",
    "    elif(score<5 and score >=2.5):\n",
    "        return \"可能新聞不在新聞資料庫內，或是有爭議無法評定\"\n",
    "    else:\n",
    "        return \"我們認為是真新聞\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import pymongo\n",
    "import re\n",
    "import keras\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_dict_path = './model/corpora_dict.dict'\n",
    "tfidf_model_path = \"./model/tfidf.model\"\n",
    "index_path = \"./model/simIndex.index\"\n",
    "\n",
    "jieba.set_dictionary(\"dict.txt.big.txt\")\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"semester\"]\n",
    "mycol = mydb[\"ettoday\"]\n",
    "\n",
    "tfidf = models.TfidfModel.load(tfidf_model_path)\n",
    "dictionary = corpora.Dictionary.load(corpora_dict_path)\n",
    "index = similarities.SparseMatrixSimilarity.load(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('5da6ec3c59aa7d15bc17ca58'), 'title': '快訊／高嘉瑜晚間好奇找阿北求證\\u3000柯P終於「一句話」解答了'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca59'), 'title': '美眉的夏天／最HOT名單出爐\\u3000她激戰搶下冠軍抱千元大獎'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca5a'), 'title': '搭西寧軍艦南偵\\u300022名教師登太平島深化主權意識'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca5c'), 'title': '桃園區慶讚中元水燈排車繞境\\u3000傳承百年特色慶典'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca61'), 'title': '鳳飛飛故事展、電影展…等紀念活動\\u3000緬懷永遠的國民天后'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca5d'), 'title': '韓國瑜選總統8月3日從桃園出發\\u3000要讓全國看到藍軍團結力量'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca5b'), 'title': '規劃「個人服裝包」\\u3000國軍新兵服裝用APP快速搞定'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca5e'), 'title': '嘉義「火燈夜巡、大士爺祭」深獲在地認同\\u3000下一步推向國際'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca62'), 'title': '台民黨「不分區名單」她第一個被點名！\\u3000柯文哲傾向不選才組黨'}, {'_id': ObjectId('5da6ec3c59aa7d15bc17ca63'), 'title': '影／她吃藥睡死…起床驚見「手被蟑螂咬」模樣超慘\\u3000網加碼曝：而且非常痛'}]\n"
     ]
    }
   ],
   "source": [
    "all_ettoday = []\n",
    "for i in mycol.find({},{\"title\":1}):\n",
    "    all_ettoday.append(i)\n",
    "print(all_ettoday[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSims(sentence):\n",
    "    sentence = re.sub(\"\\W+\",\"\",sentence)\n",
    "    texts = jieba.cut(sentence)\n",
    "    new_vec = dictionary.doc2bow(texts)\n",
    "    new_vec_tfidf = tfidf[new_vec]\n",
    "    return index[new_vec_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(ObjectId('5da6ec3c59aa7d15bc17ca58'), '高嘉瑜晚間好奇找阿北求證柯P終於一句話解答了'), (ObjectId('5da6ec3c59aa7d15bc17ca59'), '美眉的夏天最HOT名單出爐她激戰搶下冠軍抱千元大獎'), (ObjectId('5da6ec3c59aa7d15bc17ca5a'), '搭西寧軍艦南偵22名教師登太平島深化主權意識'), (ObjectId('5da6ec3c59aa7d15bc17ca5c'), '桃園區慶讚中元水燈排車繞境傳承百年特色慶典'), (ObjectId('5da6ec3c59aa7d15bc17ca61'), '鳳飛飛故事展電影展等紀念活動緬懷永遠的國民天后'), (ObjectId('5da6ec3c59aa7d15bc17ca5d'), '韓國瑜選總統8月3日從桃園出發要讓全國看到藍軍團結力量'), (ObjectId('5da6ec3c59aa7d15bc17ca5b'), '規劃個人服裝包國軍新兵服裝用APP快速搞定'), (ObjectId('5da6ec3c59aa7d15bc17ca5e'), '嘉義火燈夜巡大士爺祭深獲在地認同下一步推向國際'), (ObjectId('5da6ec3c59aa7d15bc17ca62'), '台民黨不分區名單她第一個被點名柯文哲傾向不選才組黨'), (ObjectId('5da6ec3c59aa7d15bc17ca63'), '影她吃藥睡死起床驚見手被蟑螂咬模樣超慘網加碼曝而且非常痛')]\n"
     ]
    }
   ],
   "source": [
    "clean_q = lambda sentence: re.sub(\"\\W+\",\"\",re.sub(\"快訊\",\"\",sentence[\"title\"]))\n",
    "all_dict = [(sentence[\"_id\"],clean_q(sentence)) for sentence in all_ettoday]\n",
    "print(all_dict[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\program\\semester_final\\dict.txt.big.txt ...\n",
      "Loading model from cache C:\\Users\\PC-Henry\\AppData\\Local\\Temp\\jieba.u202fd84447beda33a25aefd770cfa382.cache\n",
      "Loading model cost 1.246 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49663\n",
      "28373\n"
     ]
    }
   ],
   "source": [
    "sims = getSims(\"韓國瑜宣布選總統，為人民發聲。\")\n",
    "print(len(sims))\n",
    "print(np.argmax(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
